{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Week 5: LASSO Assignment 1\n",
    "\n",
    "In this assignment, you will use LASSO to select features, building on a pre-implemented solver for LASSO (using GraphLab Create, though you can use other solvers). You will:\n",
    "\n",
    "- Run LASSO with different L1 penalties.\n",
    "- Choose best L1 penalty using a validation set.\n",
    "- Choose best L1 penalty using a validation set, with additional constraint on the size of subset.\n",
    "\n",
    "In the second assignment, you will implement your own LASSO solver, using coordinate descent.\n",
    "\n",
    "If you are using scikit-learn with Pandas:\n",
    "\n",
    "The instructions may apply to other tools, but the set of parameters are specific to scikit-learn.\n",
    "\n",
    "## 0. Load the sales dataset using Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':float, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}\n",
    "\n",
    "sales = pd.read_csv('kc_house_data.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create new features by performing following transformation on inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log, sqrt\n",
    "\n",
    "sales['sqft_living_sqrt'] = sales['sqft_living'].apply(sqrt)\n",
    "sales['sqft_lot_sqrt'] = sales['sqft_lot'].apply(sqrt)\n",
    "sales['bedrooms_square'] = sales['bedrooms']*sales['bedrooms']\n",
    "sales['floors_square'] = sales['floors']*sales['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since 1^2 = 1 but 4^2 = 16. Consequently this variable will mostly affect houses with many bedrooms.\n",
    "\n",
    "- On the other hand, taking square root of sqft_living will decrease the separation between big house and small house. The owner may not be exactly twice as happy for getting a house that is twice as big."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using the entire house dataset, learn regression weights using an L1 penalty of 5e2. \n",
    "\n",
    "Make sure to add \"normalize=True\" when creating the Lasso object. Refer to the following code snippet for the list of features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=500.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=True, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model  # using scikit-learn\n",
    "\n",
    "all_features = [\n",
    "    'bedrooms',\n",
    "    'bedrooms_square',\n",
    "    'bathrooms',\n",
    "    'sqft_living',\n",
    "    'sqft_living_sqrt',\n",
    "    'sqft_lot',\n",
    "    'sqft_lot_sqrt',\n",
    "    'floors',\n",
    "    'floors_square',\n",
    "    'waterfront',\n",
    "    'view',\n",
    "    'condition',\n",
    "    'grade',\n",
    "    'sqft_above',\n",
    "    'sqft_basement',\n",
    "    'yr_built', \n",
    "    'yr_renovated'\n",
    "]\n",
    "\n",
    "model_all = linear_model.Lasso(alpha=5e2, normalize=True) # set parameters\n",
    "model_all.fit(sales[all_features], sales['price']) # learn weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quiz Question: Which features have been chosen by LASSO, i.e. which features were assigned nonzero weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sqft_living' 'view' 'grade']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.array(all_features)[model_all.coef_ != 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. To find a good L1 penalty, we will explore multiple values using a validation set. \n",
    "\n",
    "Let us do three way split into train, validation, and test sets. Download the provided csv files containing training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing = pd.read_csv('wk3_kc_house_test_data.csv', dtype=dtype_dict)\n",
    "training = pd.read_csv('wk3_kc_house_train_data.csv', dtype=dtype_dict)\n",
    "validation = pd.read_csv('wk3_kc_house_valid_data.csv', dtype=dtype_dict)\n",
    "\n",
    "testing['sqft_living_sqrt'] = testing['sqft_living'].apply(sqrt)\n",
    "testing['sqft_lot_sqrt'] = testing['sqft_lot'].apply(sqrt)\n",
    "testing['bedrooms_square'] = testing['bedrooms']*testing['bedrooms']\n",
    "testing['floors_square'] = testing['floors']*testing['floors']\n",
    "\n",
    "training['sqft_living_sqrt'] = training['sqft_living'].apply(sqrt)\n",
    "training['sqft_lot_sqrt'] = training['sqft_lot'].apply(sqrt)\n",
    "training['bedrooms_square'] = training['bedrooms']*training['bedrooms']\n",
    "training['floors_square'] = training['floors']*training['floors']\n",
    "\n",
    "validation['sqft_living_sqrt'] = validation['sqft_living'].apply(sqrt)\n",
    "validation['sqft_lot_sqrt'] = validation['sqft_lot'].apply(sqrt)\n",
    "validation['bedrooms_square'] = validation['bedrooms']*validation['bedrooms']\n",
    "validation['floors_square'] = validation['floors']*validation['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Now for each l1_penalty in [10^1, 10^1.5, 10^2, 10^2.5, ..., 10^7] (to get this in Python, type np.logspace(1, 7, num=13).)\n",
    "\n",
    "- Learn a model on TRAINING data using the specified l1_penalty. Make sure to specify normalize=True in the constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0 3.982133273e+14\n",
      "31.6227766017 3.99041900253e+14\n",
      "100.0 4.29791604073e+14\n",
      "316.227766017 4.63739831045e+14\n",
      "1000.0 6.45898733634e+14\n",
      "3162.27766017 1.22250685943e+15\n",
      "10000.0 1.22250685943e+15\n",
      "31622.7766017 1.22250685943e+15\n",
      "100000.0 1.22250685943e+15\n",
      "316227.766017 1.22250685943e+15\n",
      "1000000.0 1.22250685943e+15\n",
      "3162277.66017 1.22250685943e+15\n",
      "10000000.0 1.22250685943e+15\n"
     ]
    }
   ],
   "source": [
    "rss = lambda y_hat, y: np.dot((y - y_hat).T, (y-y_hat))\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "costs = []\n",
    "\n",
    "for l1_penalty in np.logspace(1,7,num=13):\n",
    "    model = linear_model.Lasso(alpha=l1_penalty, normalize=True)\n",
    "    model.fit(training[all_features], training['price'])\n",
    "    \n",
    "    predictions = model.predict(validation[all_features])\n",
    "    print(l1_penalty, mean_squared_error(validation['price'], predictions) * len(validation['price']))\n",
    "#     print(mean_srss(predictions, validation['price']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the RSS on VALIDATION for the current model (print or save the RSS)\n",
    "Report which L1 penalty produced the lower RSS on VALIDATION.\n",
    "\n",
    "## 6. Quiz Question: Which was the best value for the l1_penalty, i.e. which value of l1_penalty produced the lowest RSS on V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Now that you have selected an L1 penalty, compute the RSS on TEST data for the model with the best L1 penalty.\n",
    "\n",
    "## 8. Quiz Question: Using the best L1 penalty, how many nonzero weights do you have? Count the number of nonzero coefficients first, and add 1 if the intercept is also nonzero. A succinct way to do this is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.Lasso(alpha=10, normalize=True)\n",
    "model.fit(training[all_features], training['price'])\n",
    "np.count_nonzero(model.coef_) + np.count_nonzero(model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. What if we absolutely wanted to limit ourselves to, say, 7 features? This may be important if we want to derive \"a rule of thumb\" --- an interpretable model that has only a few features in them.\n",
    "\n",
    "You are going to implement a simple, two phase procedure to achieve this goal:\n",
    "\n",
    "Explore a large range of ‘l1_penalty’ values to find a narrow region of ‘l1_penalty’ values where models are likely to have the desired number of non-zero weights.\n",
    "Further explore the narrow region you found to find a good value for ‘l1_penalty’ that achieves the desired sparsity. Here, we will again use a validation set to choose the best value for ‘l1_penalty’.\n",
    "10. Assign 7 to the variable ‘max_nonzeros’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0 15\n",
      "14.3844988829 15\n",
      "20.6913808111 15\n",
      "29.7635144163 15\n",
      "42.8133239872 13\n",
      "61.5848211066 12\n",
      "88.586679041 11\n",
      "127.42749857 10\n",
      "183.298071083 7\n",
      "263.665089873 6\n",
      "379.269019073 6\n",
      "545.559478117 6\n",
      "784.759970351 5\n",
      "1128.83789168 3\n",
      "1623.77673919 3\n",
      "2335.72146909 2\n",
      "3359.81828628 1\n",
      "4832.93023857 1\n",
      "6951.92796178 1\n",
      "10000.0 1\n"
     ]
    }
   ],
   "source": [
    "for l1_penalty in np.logspace(1,4,num=20):\n",
    "    model = linear_model.Lasso(alpha=l1_penalty, normalize=True)\n",
    "    model.fit(training[all_features], training['price'])\n",
    "    \n",
    "    print(l1_penalty, np.count_nonzero(model.coef_) + np.count_nonzero(model.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156.109096739 7 4.40037365263e+14\n",
      "163.279496281 7 4.40777489642e+14\n",
      "170.449895824 7 4.4156669809e+14\n",
      "177.620295366 7 4.42406413189e+14\n",
      "184.790694908 7 4.43296716874e+14\n",
      "191.96109445 7 4.44239780526e+14\n",
      "199.131493993 7 4.45230739843e+14\n"
     ]
    }
   ],
   "source": [
    "for l1_penalty in np.linspace(127.42749857,263.665089873,num=20):\n",
    "    model = linear_model.Lasso(alpha=l1_penalty, normalize=True)\n",
    "    model.fit(training[all_features], training['price'])\n",
    "    \n",
    "    predictions = model.predict(validation[all_features])\n",
    "    error = mean_squared_error(validation['price'], predictions) * len(validation['price'])\n",
    "    non0 = np.count_nonzero(model.coef_) + np.count_nonzero(model.intercept_)\n",
    "    if (non0 == 7): print(l1_penalty, non0, error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bathrooms' 'sqft_living' 'waterfront' 'view' 'grade' 'yr_built']\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.Lasso(alpha=156.109096739, normalize=True)\n",
    "model.fit(training[all_features], training['price'])\n",
    "print(np.array(all_features)[model.coef_ != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
